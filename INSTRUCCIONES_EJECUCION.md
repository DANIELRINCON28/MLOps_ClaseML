# üìñ Instrucciones de Ejecuci√≥n - Pipeline MLOps de Detecci√≥n de Fraude

## üéØ Objetivo

Este documento proporciona una gu√≠a paso a paso para ejecutar el pipeline completo de MLOps para detecci√≥n de fraude.

## ‚è±Ô∏è Tiempo Estimado

- **Setup inicial:** 10 minutos
- **Ejecuci√≥n completa:** 30-60 minutos (dependiendo del hardware)

---

## üìã Paso 0: Preparaci√≥n del Entorno

### 0.1 Verificar Python

Abre PowerShell y verifica la versi√≥n de Python:

```powershell
python --version
```

Debe ser Python 3.8 o superior.

### 0.2 Navegar al directorio del proyecto

```powershell
cd C:\Users\Danie\OneDrive\Desktop\ML\PROYECTO_ML\PROYECTO_ML
```

### 0.3 Crear y activar entorno virtual

```powershell
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
.\venv\Scripts\Activate.ps1
```

Si PowerShell da error de permisos, ejecuta:

```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### 0.4 Instalar dependencias

```powershell
pip install --upgrade pip
pip install -r requirements.txt
```

**Tiempo estimado:** 5-10 minutos

### 0.5 Verificar instalaci√≥n

```powershell
python -c "import pandas, sklearn, xgboost, lightgbm, imblearn; print('‚úÖ Todas las librer√≠as instaladas')"
```

---

## üìä Paso 1: Cargar Datos

### 1.1 Ejecutar notebook de carga de datos

**Opci√≥n A: Usando Jupyter Notebook**

```powershell
jupyter notebook
```

Luego navega a: `mlops_pipeline/src/Cargar_datos.ipynb`

Ejecuta todas las celdas (Cell > Run All)

**Opci√≥n B: Usando VS Code**

1. Abre VS Code en el directorio del proyecto
2. Abre `mlops_pipeline/src/Cargar_datos.ipynb`
3. Selecciona el kernel de Python (venv)
4. Ejecuta todas las celdas

### 1.2 Verificar salidas

Deber√≠as ver:
- ‚úÖ Datos cargados: ~200,000 filas x 11 columnas
- ‚úÖ No hay valores nulos
- ‚úÖ Distribuci√≥n de fraude mostrada

### 1.3 Archivos generados

```
data/processed/
‚îú‚îÄ‚îÄ df_original.pkl
‚îî‚îÄ‚îÄ dataset_info.pkl
```

**Tiempo estimado:** 2-3 minutos

---

## üîç Paso 2: An√°lisis Exploratorio de Datos (EDA)

### 2.1 Ejecutar notebook de EDA completo

**Opci√≥n A: Jupyter Notebook**

```powershell
jupyter notebook mlops_pipeline/src/Comprension_eda_completo.ipynb
```

**Opci√≥n B: VS Code**

Abre `Comprension_eda_completo.ipynb` y ejecuta todas las celdas.

### 2.2 Revisi√≥n de an√°lisis

El notebook realizar√°:

1. **Exploraci√≥n inicial**
   - Vista general de datos
   - Informaci√≥n de tipos de datos
   - An√°lisis de nulos y duplicados

2. **Caracterizaci√≥n de variables**
   - Variables num√©ricas vs categ√≥ricas
   - Variables binarias (target)

3. **An√°lisis univariable**
   - Distribuciones de variables num√©ricas
   - Gr√°ficos de barras para categ√≥ricas
   - Detecci√≥n de outliers

4. **An√°lisis bivariable**
   - Fraude por tipo de transacci√≥n
   - Comparaci√≥n de montos
   - An√°lisis temporal

5. **An√°lisis multivariable**
   - Matriz de correlaci√≥n
   - Pairplot de variables clave

6. **Identificaci√≥n de features**
   - Features derivados de balances
   - Features binarios
   - Features de ratios
   - Features temporales

### 2.3 Archivos generados

```
data/processed/
‚îú‚îÄ‚îÄ df_eda.pkl
‚îú‚îÄ‚îÄ df_features.pkl
‚îî‚îÄ‚îÄ eda_summary.pkl

outputs/
‚îú‚îÄ‚îÄ eda_distribucion_numericas.png
‚îú‚îÄ‚îÄ eda_boxplots_numericas.png
‚îú‚îÄ‚îÄ eda_categoricas.png
‚îú‚îÄ‚îÄ eda_fraude_por_tipo.png
‚îú‚îÄ‚îÄ eda_montos_fraude.png
‚îú‚îÄ‚îÄ eda_temporal_fraude.png
‚îú‚îÄ‚îÄ eda_correlacion.png
‚îî‚îÄ‚îÄ eda_pairplot.png
```

**Tiempo estimado:** 10-15 minutos

### 2.4 Hallazgos clave a observar

- ‚ö†Ô∏è Dataset desbalanceado (~0.13% fraudes)
- üéØ Fraude SOLO en transacciones TRANSFER y CASH_OUT
- üìä Diferencias en montos entre fraude y no fraude
- üîç Patrones en balances de cuentas fraudulentas

---

## üîß Paso 3: Feature Engineering

### 3.1 Ejecutar script de feature engineering

```powershell
cd mlops_pipeline\src
python ft_engineering.py
```

### 3.2 Observar la ejecuci√≥n

El script realizar√°:

```
1. Cargando datos...
   ‚úÖ Datos cargados: ~200,000 filas x 11 columnas

2. Creando nuevas caracter√≠sticas...
   üìä Creando features de balance...
   üìä Creando features binarios...
   üìä Creando features de ratios...
   üìä Creando features temporales...
   üìä Creando features de tipo de transacci√≥n...
   üìä Creando features de magnitud...
   ‚úÖ 16 nuevas features creadas

3. Preparando datos para modelado...
   üìä Features (X): (200000, 26)
   üéØ Target (y): (200000,)
   üìä Distribuci√≥n de clases:
      - No Fraude: 199,863 (99.87%)
      - Fraude: 263 (0.13%)
   ‚úÖ Divisi√≥n completada:
      üìä Train: 160,000 muestras
      üìä Test: 40,000 muestras

4. Construyendo pipeline de preprocesamiento...
   üìä Variables num√©ricas: 24
   üìä Variables categ√≥ricas: 2
   ‚úÖ Pipeline de preprocesamiento construido

5. Ajustando y transformando datos...
   ‚úÖ Datos transformados
   üìä X_train procesado: (160000, 28)
   üìä X_test procesado: (40000, 28)

6. Guardando artefactos...
   ‚úÖ Datasets guardados
   ‚úÖ Preprocesador guardado
   ‚úÖ Dataset completo guardado
   ‚úÖ Metadatos guardados

FEATURE ENGINEERING COMPLETADO ‚úÖ
```

### 3.3 Archivos generados

```
data/processed/
‚îú‚îÄ‚îÄ X_train.pkl                          # Features de entrenamiento
‚îú‚îÄ‚îÄ X_test.pkl                           # Features de prueba
‚îú‚îÄ‚îÄ y_train.pkl                          # Target de entrenamiento
‚îú‚îÄ‚îÄ y_test.pkl                           # Target de prueba
‚îú‚îÄ‚îÄ preprocessor.pkl                     # Pipeline de preprocesamiento
‚îú‚îÄ‚îÄ df_features_complete.pkl             # Dataset completo con features
‚îî‚îÄ‚îÄ feature_engineering_metadata.pkl     # Metadata
```

**Tiempo estimado:** 3-5 minutos

---

## ü§ñ Paso 4: Entrenamiento y Evaluaci√≥n de Modelos

### 4.1 Ejecutar script de training

```powershell
# Aseg√∫rate de estar en mlops_pipeline/src
python model_training_evaluation.py
```

### 4.2 Observar la ejecuci√≥n

El script realizar√°:

```
1. Cargando datos preprocesados...
   ‚úÖ Datos cargados
   üìä X_train: (160000, 28)
   üìä X_test: (40000, 28)
   üéØ y_train: (160000,) - Fraude: 263
   üéØ y_test: (40000,) - Fraude: 37

2. Aplicando SMOTE (sampling_strategy=0.3)...
   Antes - Clase 0: 159,737, Clase 1: 263
   Despu√©s - Clase 0: 159,737, Clase 1: 47,921
   ‚úÖ SMOTE aplicado

3. Definiendo modelos...
   ‚úÖ 5 modelos definidos:
   ‚Ä¢ Logistic_Regression: Modelo lineal simple y interpretable
   ‚Ä¢ Random_Forest: Ensemble de √°rboles de decisi√≥n
   ‚Ä¢ XGBoost: Gradient Boosting optimizado
   ‚Ä¢ LightGBM: Gradient Boosting ligero y r√°pido
   ‚Ä¢ Gradient_Boosting: Gradient Boosting de sklearn

4. Entrenando modelos...
   üîÑ Entrenando Logistic_Regression...
   ‚úÖ Logistic_Regression entrenado en 12.45 segundos
   
   üîÑ Entrenando Random_Forest...
   ‚úÖ Random_Forest entrenado en 45.67 segundos
   
   üîÑ Entrenando XGBoost...
   ‚úÖ XGBoost entrenado en 23.89 segundos
   
   üîÑ Entrenando LightGBM...
   ‚úÖ LightGBM entrenado en 15.34 segundos
   
   üîÑ Entrenando Gradient_Boosting...
   ‚úÖ Gradient_Boosting entrenado en 89.12 segundos
   
   ‚úÖ Todos los modelos entrenados

5. Evaluando modelos...
   [M√©tricas para cada modelo]

6. Comparando modelos...
   [Tabla de comparaci√≥n]
   [Generando gr√°ficos...]

7. Seleccionando mejor modelo (criterio: roc_auc)...
   ü•á MEJOR MODELO: XGBoost
   Score (roc_auc): 0.9534

8. Generando reporte completo...
   ‚úÖ Reporte guardado

9. Guardando mejor modelo...
   ‚úÖ Modelo guardado en models/best_model.pkl
   ‚úÖ Metadata guardado en models/best_model_metadata.json

MODEL TRAINING & EVALUATION COMPLETADO ‚úÖ
```

### 4.3 Archivos generados

```
models/
‚îú‚îÄ‚îÄ best_model.pkl                    # Mejor modelo entrenado
‚îî‚îÄ‚îÄ best_model_metadata.json          # Metadata del modelo

outputs/
‚îú‚îÄ‚îÄ model_comparison.csv              # Tabla de comparaci√≥n
‚îú‚îÄ‚îÄ evaluation_report.json            # Reporte JSON
‚îú‚îÄ‚îÄ metrics_comparison.png            # Gr√°fico de m√©tricas
‚îú‚îÄ‚îÄ roc_curves.png                    # Curvas ROC
‚îú‚îÄ‚îÄ pr_curves.png                     # Curvas Precision-Recall
‚îî‚îÄ‚îÄ confusion_matrices.png            # Matrices de confusi√≥n
```

**Tiempo estimado:** 5-10 minutos (dependiendo del hardware)

### 4.4 Revisar resultados

#### Ver tabla de comparaci√≥n

```powershell
# Ver en pandas
python -c "import pandas as pd; df = pd.read_csv('../../outputs/model_comparison.csv'); print(df)"
```

#### Ver reporte JSON

```powershell
# Ver en consola
type ..\..\outputs\evaluation_report.json
```

#### Abrir gr√°ficos

Navega a la carpeta `outputs/` y abre los archivos PNG:

- `metrics_comparison.png` - Comparaci√≥n de todas las m√©tricas
- `roc_curves.png` - Curvas ROC de todos los modelos
- `pr_curves.png` - Curvas Precision-Recall
- `confusion_matrices.png` - Matrices de confusi√≥n

---

## üìä Paso 5: Interpretaci√≥n de Resultados

### 5.1 Revisar m√©tricas del mejor modelo

El mejor modelo (usualmente XGBoost o LightGBM) deber√≠a tener:

- **ROC-AUC:** > 0.90 ‚úÖ
- **PR-AUC:** > 0.70 ‚úÖ
- **F1-Score:** > 0.75 ‚úÖ
- **Recall:** > 0.80 ‚úÖ (crucial para fraude)
- **Precision:** > 0.70 ‚úÖ

### 5.2 Analizar curvas ROC

- Curva m√°s alejada de la diagonal = mejor modelo
- √Årea bajo la curva (AUC) m√°s cercana a 1.0 = mejor

### 5.3 Analizar Precision-Recall

- Importante para datasets desbalanceados
- Muestra el trade-off entre precisi√≥n y recall
- AUC > 0.70 es excelente para fraude

### 5.4 Interpretar matriz de confusi√≥n

```
                 Predicted
                 No    Fraude
Actual No       [TN]   [FP]
       Fraude   [FN]   [TP]
```

**M√©tricas importantes:**
- **True Positives (TP):** Fraudes correctamente detectados
- **False Negatives (FN):** Fraudes NO detectados ‚ùå (minimizar)
- **False Positives (FP):** Falsos positivos (minimizar)
- **True Negatives (TN):** No fraudes correctamente clasificados

---

## üéØ Criterios de Selecci√≥n del Mejor Modelo

Seg√∫n la imagen adjunta, se eval√∫an 3 aspectos:

### 1. **Performance** üéØ

- ROC-AUC > 0.90
- PR-AUC > 0.70
- F1-Score balanceado
- Recall alto (detectar la mayor√≠a de fraudes)

### 2. **Consistency** üîÑ

- Resultados estables
- No overfitting (train vs test similar)
- Generalizaci√≥n adecuada

### 3. **Scalability** ‚ö°

- Tiempo de entrenamiento < 2 minutos
- Uso de memoria razonable
- Capacidad de procesar en tiempo real

**Modelo t√≠picamente seleccionado:** XGBoost o LightGBM

---

## ‚úÖ Verificaci√≥n Final

### Checklist de archivos generados

Verifica que existan los siguientes archivos:

```powershell
# Datos
dir data\processed\

# Modelos
dir models\

# Outputs
dir outputs\
```

Deber√≠as tener:

```
‚úÖ data/processed/
   ‚úÖ df_original.pkl
   ‚úÖ X_train.pkl
   ‚úÖ X_test.pkl
   ‚úÖ y_train.pkl
   ‚úÖ y_test.pkl
   ‚úÖ preprocessor.pkl
   ‚úÖ df_features_complete.pkl
   ‚úÖ *_metadata.pkl

‚úÖ models/
   ‚úÖ best_model.pkl
   ‚úÖ best_model_metadata.json

‚úÖ outputs/
   ‚úÖ eda_*.png (8 gr√°ficos)
   ‚úÖ metrics_comparison.png
   ‚úÖ roc_curves.png
   ‚úÖ pr_curves.png
   ‚úÖ confusion_matrices.png
   ‚úÖ model_comparison.csv
   ‚úÖ evaluation_report.json
```

---

## üîÑ Uso del Modelo Entrenado

### Cargar el mejor modelo

```python
import pickle

# Cargar modelo
with open('models/best_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Cargar preprocessor
with open('data/processed/preprocessor.pkl', 'rb') as f:
    preprocessor = pickle.load(f)

# Cargar datos de prueba
import pandas as pd
X_test = pd.read_pickle('data/processed/X_test.pkl')
y_test = pd.read_pickle('data/processed/y_test.pkl')

# Hacer predicciones
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

print(f"Predicciones realizadas: {len(y_pred)}")
print(f"Fraudes detectados: {y_pred.sum()}")
```

### Predecir en nuevos datos

```python
# Cargar nuevos datos
new_data = pd.read_csv('nuevos_datos.csv')

# Aplicar feature engineering (usar las mismas transformaciones)
# ... (aplicar las mismas transformaciones de ft_engineering.py)

# Preprocesar
new_data_processed = preprocessor.transform(new_data)

# Predecir
predictions = model.predict(new_data_processed)
probabilities = model.predict_proba(new_data_processed)[:, 1]

# Transacciones con alta probabilidad de fraude
fraud_threshold = 0.5
high_risk = probabilities > fraud_threshold

print(f"Transacciones de alto riesgo: {high_risk.sum()}")
```

---

## üêõ Soluci√≥n de Problemas

### Problema 1: "Memory Error"

**Soluci√≥n:** Trabajar con una muestra m√°s peque√±a

```python
# En ft_engineering.py, modificar load_data():
df_sample = self.df.sample(n=50000, random_state=42)
self.df = df_sample
```

### Problema 2: SMOTE toma mucho tiempo

**Soluci√≥n:** Reducir sampling_strategy

```python
# En model_training_evaluation.py:
trainer.apply_smote(sampling_strategy=0.1)  # En lugar de 0.3
```

### Problema 3: Error al importar librer√≠as

**Soluci√≥n:** Reinstalar dependencias

```powershell
pip uninstall -y scikit-learn xgboost lightgbm imbalanced-learn
pip install scikit-learn xgboost lightgbm imbalanced-learn
```

### Problema 4: Jupyter no encuentra el kernel

**Soluci√≥n:** Instalar kernel de IPython

```powershell
pip install ipykernel
python -m ipykernel install --user --name=venv
```

---

## üìö Recursos Adicionales

### Documentaci√≥n

- [Scikit-learn](https://scikit-learn.org/)
- [XGBoost](https://xgboost.readthedocs.io/)
- [LightGBM](https://lightgbm.readthedocs.io/)
- [Imbalanced-learn](https://imbalanced-learn.org/)

### Conceptos clave

- **SMOTE:** Synthetic Minority Over-sampling Technique
- **ROC-AUC:** Receiver Operating Characteristic - Area Under Curve
- **PR-AUC:** Precision-Recall Area Under Curve
- **ColumnTransformer:** Scikit-learn transformer for different column types

---

## üìû Soporte

Si encuentras problemas:

1. Revisa esta gu√≠a completa
2. Consulta el archivo `README_COMPLETO.md`
3. Revisa los logs de error
4. Contacta al equipo de MLOps

---

**¬°Felicidades! Has completado el pipeline MLOps de detecci√≥n de fraude** üéâ

**Siguiente paso:** Implementar el despliegue del modelo (API con FastAPI) y monitoreo (Streamlit).

---

**√öltima actualizaci√≥n:** Noviembre 2025
