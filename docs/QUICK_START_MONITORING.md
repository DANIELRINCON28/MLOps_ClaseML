# ğŸš€ GUÃA RÃPIDA DE EJECUCIÃ“N - Sistema de Monitoreo

## âš¡ EjecuciÃ³n en 3 Pasos

### ğŸ“¦ Paso 1: Preparar Entorno

```powershell
# Navegar al proyecto
cd c:\Users\Danie\OneDrive\Desktop\ML\PROYECTO_ML\PROYECTO_ML

# Activar entorno virtual
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process -Force
.\MLOPS_FINAL-venv\Scripts\Activate.ps1

# Verificar instalaciÃ³n
python check_environment.py
```

---

### ğŸ” Paso 2: Ejecutar Monitoreo de Data Drift

```powershell
# Navegar a la carpeta de scripts
cd mlops_pipeline\src

# Ejecutar sistema de monitoreo
python model_monitoring.py
```

**â±ï¸ Tiempo estimado:** 2-3 minutos

**âœ… Salida esperada:**
- Archivos en `outputs/monitoring/`:
  - `drift_results_YYYYMMDD_HHMMSS.csv`
  - `alerts_YYYYMMDD_HHMMSS.json`
  - `predictions_YYYYMMDD_HHMMSS.csv`
  - `latest_summary.json`

---

### ğŸ“Š Paso 3: Abrir Dashboard Interactivo

```powershell
# Volver al directorio raÃ­z
cd ..\..

# Ejecutar aplicaciÃ³n Streamlit
streamlit run app_monitoring.py
```

**ğŸŒ URL del Dashboard:**
- Local: `http://localhost:8501`

**ğŸ¨ CaracterÃ­sticas:**
- âœ… Colores institucionales Universidad CatÃ³lica Luis AmigÃ³
- âœ… 6 secciones interactivas
- âœ… Filtros dinÃ¡micos
- âœ… GrÃ¡ficos con Plotly
- âœ… Descarga de reportes CSV

---

## ğŸ“‹ Secciones del Dashboard

| SecciÃ³n | DescripciÃ³n | Funcionalidades |
|---------|-------------|-----------------|
| ğŸ  **Resumen General** | Vista general del estado del sistema | MÃ©tricas clave, grÃ¡fico de severidad, top 10 variables |
| ğŸ“ˆ **MÃ©tricas de Drift** | AnÃ¡lisis detallado por variable | Gauges KS/PSI/JS, filtros, estadÃ­sticas comparativas |
| ğŸš¨ **Alertas** | Alertas automÃ¡ticas por severidad | Alertas crÃ­ticas, advertencias, recomendaciones |
| ğŸ¯ **Predicciones** | Resultados del modelo | DistribuciÃ³n, tasa de fraude, descarga CSV |
| ğŸ“Š **GrÃ¡ficos EDA** | Visualizaciones del anÃ¡lisis exploratorio | Tabs por categorÃ­a, imÃ¡genes interactivas |
| ğŸ“‹ **Tabla de Datos** | Explorador de datos completo | Drift results, predicciones, alertas en tabla |

---

## ğŸ¯ InterpretaciÃ³n RÃ¡pida de Alertas

### ğŸš¨ CRÃTICO (Rojo)
- **AcciÃ³n:** Revisar inmediatamente
- **RecomendaciÃ³n:** Considerar reentrenamiento
- **Criterio:** KS/PSI/JS â‰¥ 0.2

### âš ï¸ ADVERTENCIA (Amarillo)
- **AcciÃ³n:** Monitorear de cerca
- **RecomendaciÃ³n:** Preparar plan de reentrenamiento
- **Criterio:** 0.1 â‰¤ KS/PSI/JS < 0.2

### âœ… NORMAL (Verde)
- **AcciÃ³n:** Continuar monitoreo regular
- **RecomendaciÃ³n:** Sin cambios necesarios
- **Criterio:** KS/PSI/JS < 0.1

---

## ğŸ”„ Comandos Ãštiles

### Detener el Dashboard
```powershell
# Presionar Ctrl + C en la terminal donde corre Streamlit
```

### Cambiar Puerto del Dashboard
```powershell
streamlit run app_monitoring.py --server.port 8502
```

### Ver Logs del Monitoreo
```powershell
# Los logs se muestran directamente en la consola durante la ejecuciÃ³n
python model_monitoring.py > logs_monitoreo.txt 2>&1
```

### Limpiar Archivos Antiguos
```powershell
# Eliminar archivos de monitoreo de mÃ¡s de 30 dÃ­as
cd outputs\monitoring
Get-ChildItem -Filter "drift_results_*.csv" | Where-Object {$_.LastWriteTime -lt (Get-Date).AddDays(-30)} | Remove-Item
```

---

## ğŸ“ Estructura de Archivos Generados

```
PROYECTO_ML/
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ drift_results_20251106_143022.csv     â† MÃ©tricas de drift
â”‚   â”‚   â”œâ”€â”€ alerts_20251106_143022.json           â† Alertas generadas
â”‚   â”‚   â”œâ”€â”€ predictions_20251106_143022.csv       â† Predicciones
â”‚   â”‚   â””â”€â”€ latest_summary.json                   â† Resumen Ãºltimo monitoreo
â”‚   â”‚
â”‚   â””â”€â”€ eda_*.png                                  â† GrÃ¡ficos del EDA
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pkl                             â† Modelo entrenado
â”‚   â””â”€â”€ best_model_metadata.json                   â† Metadata del modelo
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ X_train.pkl, X_test.pkl               â† Datos procesados
â”‚       â””â”€â”€ preprocessor.pkl                       â† Pipeline de transformaciÃ³n
â”‚
â”œâ”€â”€ mlops_pipeline/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ model_monitoring.py                    â† Script de monitoreo
â”‚       â”œâ”€â”€ Cargar_datos.ipynb                     â† Notebook de carga
â”‚       â”œâ”€â”€ Comprension_eda_completo.ipynb         â† Notebook de EDA
â”‚       â”œâ”€â”€ ft_engineering.py                      â† Feature engineering
â”‚       â””â”€â”€ model_training_evaluation.py           â† Entrenamiento
â”‚
â””â”€â”€ app_monitoring.py                              â† Dashboard Streamlit
```

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Modificar Umbrales de Drift

Editar `mlops_pipeline/src/model_monitoring.py`:

```python
# LÃ­nea ~41
self.thresholds = {
    'ks_stat': 0.1,      # Kolmogorov-Smirnov
    'psi': 0.2,          # Population Stability Index
    'js_divergence': 0.1, # Jensen-Shannon
    'chi2_pvalue': 0.05   # Chi-cuadrado
}

# Valores mÃ¡s estrictos (detecta cambios mÃ¡s pequeÃ±os):
self.thresholds = {
    'ks_stat': 0.05,
    'psi': 0.1,
    'js_divergence': 0.05,
    'chi2_pvalue': 0.05
}

# Valores mÃ¡s permisivos (menos alertas):
self.thresholds = {
    'ks_stat': 0.15,
    'psi': 0.25,
    'js_divergence': 0.15,
    'chi2_pvalue': 0.05
}
```

### Modificar TamaÃ±o de Muestra

```python
# En model_monitoring.py, lÃ­nea ~608

# AnÃ¡lisis rÃ¡pido (desarrollo)
drift_results = monitor.detect_drift(sample_size=1000)

# AnÃ¡lisis balanceado (recomendado)
drift_results = monitor.detect_drift(sample_size=5000)

# AnÃ¡lisis completo (producciÃ³n)
drift_results = monitor.detect_drift(sample_size=None)
```

---

## ğŸ“ Caso de Uso Completo

### Escenario: Monitoreo Semanal

**Lunes 9:00 AM - Ejecutar Monitoreo:**

```powershell
# 1. Activar entorno
.\MLOPS_FINAL-venv\Scripts\Activate.ps1

# 2. Ejecutar monitoreo
cd mlops_pipeline\src
python model_monitoring.py

# 3. Revisar salida
# Si hay alertas crÃ­ticas â†’ notificar al equipo
# Si hay advertencias â†’ agendar revisiÃ³n
```

**Salida Ejemplo:**
```
ğŸš¨ ALERTA CRÃTICA: 2 variables con drift severo detectado
Variables: amount, oldbalanceOrg
RecomendaciÃ³n: ACCIÃ“N INMEDIATA REQUERIDA - Considerar reentrenamiento

âš ï¸ ADVERTENCIA: 1 variables con drift moderado
Variables: balance_diff_orig
RecomendaciÃ³n: Monitorear de cerca estas variables
```

**AcciÃ³n Tomada:**
1. âœ… Abrir dashboard para anÃ¡lisis detallado
2. âœ… Revisar distribuciones de `amount` y `oldbalanceOrg`
3. âœ… Investigar causa (cambio en comportamiento de usuarios, inflaciÃ³n, etc.)
4. âœ… Decidir: Â¿Reentrenar modelo? Â¿Ajustar umbrales?
5. âœ… Documentar decisiÃ³n en bitÃ¡cora

---

## ğŸ†˜ Troubleshooting RÃ¡pido

### Problema: "No module named 'streamlit'"
**SoluciÃ³n:**
```powershell
pip install streamlit plotly
```

### Problema: "No se encontraron archivos de monitoreo"
**SoluciÃ³n:**
```powershell
cd mlops_pipeline\src
python model_monitoring.py
```

### Problema: "FileNotFoundError: best_model.pkl"
**SoluciÃ³n:**
```powershell
# Entrenar el modelo primero
cd mlops_pipeline\src
python model_training_evaluation.py
```

### Problema: Puerto 8501 en uso
**SoluciÃ³n:**
```powershell
streamlit run app_monitoring.py --server.port 8502
```

### Problema: Dashboard no carga grÃ¡ficos EDA
**SoluciÃ³n:**
```powershell
# Ejecutar el notebook de EDA primero
jupyter notebook mlops_pipeline/src/Comprension_eda_completo.ipynb
# Ejecutar todas las celdas
```

---

## ğŸ“§ Soporte

**Proyecto:** Pipeline MLOps - DetecciÃ³n de Fraude  
**Universidad:** CatÃ³lica Luis AmigÃ³  
**Fecha:** Noviembre 2025

**DocumentaciÃ³n Completa:**
- ğŸ“„ `INSIGHTS.md` - Caso de negocio y hallazgos
- ğŸ“– `README_MONITOREO.md` - GuÃ­a detallada de monitoreo
- ğŸ“‹ `README_COMPLETO.md` - DocumentaciÃ³n general del proyecto
- ğŸš€ `INSTRUCCIONES_EJECUCION.md` - GuÃ­a paso a paso completa

---

**ğŸ¯ Â¡Listo para detectar data drift y mantener tu modelo de fraude en Ã³ptimas condiciones!**

ğŸ”µ **Universidad CatÃ³lica Luis AmigÃ³** | ğŸŸ  **MLOps** | ğŸ” **Fraud Detection**
