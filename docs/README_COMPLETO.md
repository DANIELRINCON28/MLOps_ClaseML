# ğŸš€ Proyecto MLOps - DetecciÃ³n de Fraude en Transacciones Financieras

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline completo de MLOps para la detecciÃ³n de fraude en transacciones financieras utilizando el dataset PaySim. El pipeline incluye desde la carga de datos hasta el entrenamiento y evaluaciÃ³n de modelos de Machine Learning.

## ğŸ“ Estructura del Proyecto

```
PROYECTO_ML/
â”œâ”€â”€ Base_datos.csv                      # Dataset original
â”œâ”€â”€ config.json                         # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ requirements.txt                    # Dependencias Python
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ INSTRUCCIONES_EJECUCION.md        # GuÃ­a de ejecuciÃ³n paso a paso
â”‚
â”œâ”€â”€ data/                              # Datos procesados
â”‚   â””â”€â”€ processed/                     # Datos despuÃ©s de cada etapa
â”‚       â”œâ”€â”€ df_original.pkl
â”‚       â”œâ”€â”€ df_features_complete.pkl
â”‚       â”œâ”€â”€ X_train.pkl
â”‚       â”œâ”€â”€ X_test.pkl
â”‚       â”œâ”€â”€ y_train.pkl
â”‚       â”œâ”€â”€ y_test.pkl
â”‚       â”œâ”€â”€ preprocessor.pkl
â”‚       â””â”€â”€ *_metadata.pkl
â”‚
â”œâ”€â”€ models/                            # Modelos entrenados
â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â””â”€â”€ best_model_metadata.json
â”‚
â”œâ”€â”€ outputs/                           # GrÃ¡ficos y reportes
â”‚   â”œâ”€â”€ eda_*.png
â”‚   â”œâ”€â”€ metrics_comparison.png
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â”œâ”€â”€ pr_curves.png
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ model_comparison.csv
â”‚   â””â”€â”€ evaluation_report.json
â”‚
â””â”€â”€ mlops_pipeline/
    â””â”€â”€ src/
        â”œâ”€â”€ Cargar_datos.ipynb                 # 1. Carga de datos
        â”œâ”€â”€ Comprension_eda.ipynb              # 2. AnÃ¡lisis exploratorio
        â”œâ”€â”€ Comprension_eda_completo.ipynb     # 2. EDA completo
        â”œâ”€â”€ ft_engineering.py                  # 3. Feature Engineering
        â”œâ”€â”€ model_training_evaluation.py       # 4. Entrenamiento y evaluaciÃ³n
        â”œâ”€â”€ model_deploy.ipynb                 # 5. Despliegue
        â”œâ”€â”€ model_evaluation.ipynb             # 6. EvaluaciÃ³n adicional
        â””â”€â”€ model_monitoring.ipynb             # 7. Monitoreo
```

## ğŸ¯ Objetivos del Proyecto

1. **Detectar transacciones fraudulentas** con alta precisiÃ³n
2. **Implementar un pipeline MLOps completo** y reproducible
3. **Crear modelos escalables y monitoreables**
4. **Generar insights sobre patrones de fraude**

## ğŸ“Š Dataset

**Nombre:** PaySim - SimulaciÃ³n de transacciones mÃ³viles de dinero

**TamaÃ±o:** ~200,000 transacciones

**Variables:**
- `step`: Unidad de tiempo (1 step = 1 hora)
- `type`: Tipo de transacciÃ³n (CASH_IN, CASH_OUT, DEBIT, PAYMENT, TRANSFER)
- `amount`: Monto de la transacciÃ³n
- `nameOrig`: ID del cliente origen
- `oldbalanceOrg`: Balance inicial origen
- `newbalanceOrig`: Balance final origen
- `nameDest`: ID del cliente destino
- `oldbalanceDest`: Balance inicial destino
- `newbalanceDest`: Balance final destino
- `isFraud`: **Variable objetivo** (1 = fraude, 0 = legÃ­timo)
- `isFlaggedFraud`: Flag del sistema (no usar en entrenamiento)

**CaracterÃ­sticas del dataset:**
- âš ï¸ Altamente desbalanceado (~0.13% fraudes)
- ğŸ¯ Fraude solo ocurre en transacciones TRANSFER y CASH_OUT
- âœ… Sin valores nulos
- âœ… Sin duplicados

## ğŸ”§ TecnologÃ­as Utilizadas

### Python Libraries

```
pandas                # ManipulaciÃ³n de datos
numpy                 # Operaciones numÃ©ricas
scikit-learn         # Machine Learning
xgboost              # Gradient Boosting
lightgbm             # Gradient Boosting ligero
imbalanced-learn     # Manejo de clases desbalanceadas
matplotlib           # VisualizaciÃ³n
seaborn              # VisualizaciÃ³n estadÃ­stica
```

### TÃ©cnicas de ML

- **Balanceo de clases:** SMOTE (Synthetic Minority Over-sampling Technique)
- **Feature Engineering:** Variables derivadas de balances, ratios, temporales
- **Preprocesamiento:** ColumnTransformer con pipelines especializados
- **Modelos evaluados:**
  - Logistic Regression
  - Random Forest
  - XGBoost
  - LightGBM
  - Gradient Boosting

### MÃ©tricas de EvaluaciÃ³n

- **ROC-AUC:** Ãrea bajo la curva ROC
- **PR-AUC:** PrecisiÃ³n-Recall AUC
- **F1-Score:** Media armÃ³nica de precisiÃ³n y recall
- **Precision:** ProporciÃ³n de predicciones positivas correctas
- **Recall:** ProporciÃ³n de fraudes detectados
- **Accuracy:** Exactitud general

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <repository-url>
cd PROYECTO_ML
```

### 2. Crear entorno virtual

```bash
python -m venv venv
```

### 3. Activar entorno virtual

**Windows (PowerShell):**
```powershell
.\venv\Scripts\Activate.ps1
```

**Windows (CMD):**
```cmd
venv\Scripts\activate.bat
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### 4. Instalar dependencias

```bash
pip install -r requirements.txt
```

## ğŸ“– Uso del Pipeline

### OpciÃ³n 1: EjecuciÃ³n Completa AutomÃ¡tica

Ejecutar todos los scripts en orden:

```bash
# 1. Cargar datos (ejecutar notebook o script)
python -c "import Cargar_datos"

# 2. EDA (ejecutar notebook)
jupyter notebook mlops_pipeline/src/Comprension_eda_completo.ipynb

# 3. Feature Engineering
cd mlops_pipeline/src
python ft_engineering.py

# 4. Model Training & Evaluation
python model_training_evaluation.py
```

### OpciÃ³n 2: EjecuciÃ³n Paso a Paso

Ver archivo `INSTRUCCIONES_EJECUCION.md` para una guÃ­a detallada paso a paso.

## ğŸ“Š Resultados Esperados

DespuÃ©s de ejecutar el pipeline completo, obtendrÃ¡s:

### Archivos Generados

1. **Datos Procesados:**
   - `data/processed/X_train.pkl` - Features de entrenamiento
   - `data/processed/X_test.pkl` - Features de prueba
   - `data/processed/y_train.pkl` - Target de entrenamiento
   - `data/processed/y_test.pkl` - Target de prueba

2. **Modelos:**
   - `models/best_model.pkl` - Mejor modelo entrenado
   - `models/best_model_metadata.json` - Metadata del modelo

3. **Visualizaciones:**
   - `outputs/eda_*.png` - GrÃ¡ficos del anÃ¡lisis exploratorio
   - `outputs/metrics_comparison.png` - ComparaciÃ³n de modelos
   - `outputs/roc_curves.png` - Curvas ROC
   - `outputs/pr_curves.png` - Curvas Precision-Recall
   - `outputs/confusion_matrices.png` - Matrices de confusiÃ³n

4. **Reportes:**
   - `outputs/model_comparison.csv` - Tabla de comparaciÃ³n
   - `outputs/evaluation_report.json` - Reporte completo

### MÃ©tricas TÃ­picas

Los modelos bien entrenados deberÃ­an alcanzar:

- **ROC-AUC:** > 0.90
- **PR-AUC:** > 0.70
- **F1-Score:** > 0.75
- **Recall:** > 0.80 (importante para fraude)

## ğŸ” Componentes del Pipeline

### 1. Cargar_datos.ipynb

**Objetivo:** Carga inicial del dataset y verificaciÃ³n bÃ¡sica

**Salidas:**
- Dataset cargado en memoria
- InformaciÃ³n bÃ¡sica del dataset
- Archivo pickle para uso posterior

### 2. Comprension_eda.ipynb / Comprension_eda_completo.ipynb

**Objetivo:** AnÃ¡lisis Exploratorio de Datos exhaustivo

**Incluye:**
- ExploraciÃ³n inicial de datos
- CaracterizaciÃ³n de variables
- AnÃ¡lisis univariable (distribuciones, outliers)
- AnÃ¡lisis bivariable (relaciÃ³n con target)
- AnÃ¡lisis multivariable (correlaciones, pairplot)
- IdentificaciÃ³n de transformaciones necesarias
- DefiniciÃ³n de reglas de validaciÃ³n

**Salidas:**
- MÃºltiples grÃ¡ficos de visualizaciÃ³n
- Dataset con features identificados
- Resumen del EDA

### 3. ft_engineering.py

**Objetivo:** IngenierÃ­a de caracterÃ­sticas y preprocesamiento

**Pipeline implementado:**

```
ColumnTransformer
â”œâ”€â”€ numeric_transformer (Pipeline)
â”‚   â”œâ”€â”€ SimpleImputer(strategy='median')
â”‚   â””â”€â”€ RobustScaler()
â”‚
â””â”€â”€ categoric_transformer (Pipeline)
    â”œâ”€â”€ SimpleImputer(strategy='most_frequent')
    â””â”€â”€ OneHotEncoder(drop='first', handle_unknown='ignore')
```

**Features creadas:**
- Diferencias de balance (origen y destino)
- Errores en balance
- Ratios (amount/balance)
- Features binarios (merchant, balance=0)
- Features temporales (hora, dÃ­a, weekend, night)
- Features de tipo de transacciÃ³n
- CategorÃ­as de monto

**Salidas:**
- X_train, X_test, y_train, y_test
- Preprocesador ajustado
- Metadata del feature engineering

### 4. model_training_evaluation.py

**Objetivo:** Entrenar y evaluar mÃºltiples modelos de ML

**Modelos entrenados:**
1. Logistic Regression (baseline)
2. Random Forest (ensemble robusto)
3. XGBoost (gradient boosting optimizado)
4. LightGBM (gradient boosting rÃ¡pido)
5. Gradient Boosting (sklearn)

**Proceso:**
1. Aplicar SMOTE para balanceo
2. Entrenar todos los modelos
3. Evaluar en conjunto de prueba
4. Comparar mÃ©tricas (performance, consistency, scalability)
5. Seleccionar mejor modelo
6. Generar visualizaciones y reportes

**Salidas:**
- Mejor modelo guardado
- ComparaciÃ³n de modelos (tabla y grÃ¡ficos)
- Curvas ROC y PR
- Matrices de confusiÃ³n
- Reporte de evaluaciÃ³n completo

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### CÃ³mo elegir el mejor modelo

Se evalÃºan 3 criterios principales (segÃºn imagen adjunta):

1. **Performance** ğŸ¯
   - ROC-AUC > 0.90
   - PR-AUC > 0.70
   - F1-Score balanceado

2. **Consistency** ğŸ”„
   - Resultados estables entre ejecuciones
   - Bajo overfitting (train vs test)
   - GeneralizaciÃ³n adecuada

3. **Scalability** âš¡
   - Tiempo de entrenamiento razonable
   - Uso eficiente de memoria
   - Capacidad de procesar datos en producciÃ³n

### Funciones Auxiliares

El cÃ³digo incluye dos funciones principales:

#### `summarize_classification(results_dict)`

Genera un resumen de los resultados de clasificaciÃ³n en formato tabla.

**Uso:**
```python
from model_training_evaluation import summarize_classification

summary = summarize_classification(trainer.results)
```

#### `build_model(X_train, y_train, model_type='xgboost')`

Construye y entrena un modelo especÃ­fico.

**Uso:**
```python
from model_training_evaluation import build_model

model = build_model(X_train, y_train, model_type='xgboost')
```

## ğŸ› ï¸ PersonalizaciÃ³n

### Modificar hiperparÃ¡metros

Edita el mÃ©todo `define_models()` en `model_training_evaluation.py`:

```python
'XGBoost': {
    'model': XGBClassifier(
        n_estimators=200,        # Cambiar aquÃ­
        max_depth=15,            # Cambiar aquÃ­
        learning_rate=0.05,      # Cambiar aquÃ­
        # ...
    ),
    'description': 'Gradient Boosting optimizado'
}
```

### Agregar nuevos modelos

AÃ±ade nuevos modelos al diccionario `self.models`:

```python
'Neural_Network': {
    'model': MLPClassifier(
        hidden_layer_sizes=(100, 50),
        max_iter=1000,
        random_state=42
    ),
    'description': 'Red neuronal multicapa'
}
```

### Crear nuevas features

Edita el mÃ©todo `create_features()` en `ft_engineering.py`:

```python
# Tu nueva feature
self.df_features['mi_nueva_feature'] = (
    # LÃ³gica de la feature
)
```

## ğŸ› Troubleshooting

### Error: "Memory Error"

El dataset es grande. Soluciones:

1. Trabajar con una muestra:
```python
df_sample = df.sample(n=50000, random_state=42)
```

2. Usar tipos de datos mÃ¡s eficientes:
```python
df['amount'] = df['amount'].astype('float32')
```

### Error: "SMOTE toma mucho tiempo"

Reducir el sampling_strategy:

```python
trainer.apply_smote(sampling_strategy=0.1)  # En lugar de 0.3
```

### Error: "XGBoost no instalado"

```bash
pip install xgboost
```

### Error: "LightGBM no instalado"

```bash
pip install lightgbm
```

## ğŸ“ PrÃ³ximos Pasos

1. âœ… Carga de datos
2. âœ… AnÃ¡lisis exploratorio
3. âœ… Feature Engineering
4. âœ… Model Training & Evaluation
5. â³ Model Deployment (API con FastAPI)
6. â³ Model Monitoring (Streamlit dashboard)
7. â³ CI/CD Pipeline (GitHub Actions)

## ğŸ‘¥ ContribuciÃ³n

Para contribuir al proyecto:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto es parte de un proyecto acadÃ©mico de MLOps.

## ğŸ“§ Contacto

Para preguntas o sugerencias, contactar al equipo de MLOps.

---

**Hecho con â¤ï¸ por el equipo de MLOps**

**Ãšltima actualizaciÃ³n:** Noviembre 2025
